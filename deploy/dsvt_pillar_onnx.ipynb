{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80f66a20-a14b-4980-93b4-21ebd5c2b60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.onnx\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from pcdet.config import cfg, cfg_from_yaml_file\n",
    "from pcdet.models import build_network\n",
    "from pcdet.datasets import build_dataloader\n",
    "from pcdet.utils import common_utils\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "# # import onnx\n",
    "import onnxruntime as ort\n",
    "import torch.nn as nn\n",
    "\n",
    "# from typing import Sequence, NamedTuple\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "919f3bab-9a8a-44fe-b999-993169d4d8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AllDSVTBlocksTRT(nn.Module):\n",
    "    def __init__(self, dsvtblocks_list, layer_norms_list):\n",
    "        super().__init__()\n",
    "        self.layer_norms_list = layer_norms_list\n",
    "        self.dsvtblocks_list = dsvtblocks_list\n",
    "    def forward(\n",
    "        self,\n",
    "        pillar_features,\n",
    "        set_voxel_inds_tensor_shift_0,\n",
    "        set_voxel_inds_tensor_shift_1,\n",
    "        set_voxel_masks_tensor_shift_0,\n",
    "        set_voxel_masks_tensor_shift_1,\n",
    "        pos_embed_tensor,\n",
    "    ):\n",
    "        outputs = pillar_features\n",
    "\n",
    "        residual = outputs\n",
    "        blc_id = 0\n",
    "        set_id = 0\n",
    "        set_voxel_inds = set_voxel_inds_tensor_shift_0[set_id:set_id+1].squeeze(0)\n",
    "        set_voxel_masks = set_voxel_masks_tensor_shift_0[set_id:set_id+1].squeeze(0)\n",
    "        pos_embed = pos_embed_tensor[blc_id:blc_id+1, set_id:set_id+1].squeeze(0).squeeze(0)\n",
    "        # inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed, True)\n",
    "        inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed)\n",
    "\n",
    "        outputs = self.dsvtblocks_list[blc_id].encoder_list[set_id](*inputs)\n",
    "        set_id = 1\n",
    "        set_voxel_inds = set_voxel_inds_tensor_shift_0[set_id:set_id+1].squeeze(0)\n",
    "        set_voxel_masks = set_voxel_masks_tensor_shift_0[set_id:set_id+1].squeeze(0)\n",
    "        pos_embed = pos_embed_tensor[blc_id:blc_id+1, set_id:set_id+1].squeeze(0).squeeze(0)\n",
    "        # inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed, True)\n",
    "        inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed)\n",
    "\n",
    "        outputs = self.dsvtblocks_list[blc_id].encoder_list[set_id](*inputs)\n",
    "\n",
    "        outputs = self.layer_norms_list[blc_id](residual + outputs)\n",
    "\n",
    "        residual = outputs\n",
    "        blc_id = 1\n",
    "        set_id = 0\n",
    "        set_voxel_inds = set_voxel_inds_tensor_shift_1[set_id:set_id+1].squeeze(0)\n",
    "        set_voxel_masks = set_voxel_masks_tensor_shift_1[set_id:set_id+1].squeeze(0)\n",
    "        pos_embed = pos_embed_tensor[blc_id:blc_id+1, set_id:set_id+1].squeeze(0).squeeze(0)\n",
    "        inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed)\n",
    "        # inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed, True)\n",
    "\n",
    "        outputs = self.dsvtblocks_list[blc_id].encoder_list[set_id](*inputs)\n",
    "        set_id = 1\n",
    "        set_voxel_inds = set_voxel_inds_tensor_shift_1[set_id:set_id+1].squeeze(0)\n",
    "        set_voxel_masks = set_voxel_masks_tensor_shift_1[set_id:set_id+1].squeeze(0)\n",
    "        pos_embed = pos_embed_tensor[blc_id:blc_id+1, set_id:set_id+1].squeeze(0).squeeze(0)\n",
    "        inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed)\n",
    "        # inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed, True)\n",
    "        outputs = self.dsvtblocks_list[blc_id].encoder_list[set_id](*inputs)\n",
    "\n",
    "        outputs = self.layer_norms_list[blc_id](residual + outputs)\n",
    "\n",
    "        residual = outputs\n",
    "        blc_id = 2\n",
    "        set_id = 0\n",
    "        set_voxel_inds = set_voxel_inds_tensor_shift_0[set_id:set_id+1].squeeze(0)\n",
    "        set_voxel_masks = set_voxel_masks_tensor_shift_0[set_id:set_id+1].squeeze(0)\n",
    "        pos_embed = pos_embed_tensor[blc_id:blc_id+1, set_id:set_id+1].squeeze(0).squeeze(0)\n",
    "        # inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed, True)\n",
    "        inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed)\n",
    "        outputs = self.dsvtblocks_list[blc_id].encoder_list[set_id](*inputs)\n",
    "        set_id = 1\n",
    "        set_voxel_inds = set_voxel_inds_tensor_shift_0[set_id:set_id+1].squeeze(0)\n",
    "        set_voxel_masks = set_voxel_masks_tensor_shift_0[set_id:set_id+1].squeeze(0)\n",
    "        pos_embed = pos_embed_tensor[blc_id:blc_id+1, set_id:set_id+1].squeeze(0).squeeze(0)\n",
    "        # inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed, True)\n",
    "        inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed)\n",
    "        outputs = self.dsvtblocks_list[blc_id].encoder_list[set_id](*inputs)\n",
    "\n",
    "        outputs = self.layer_norms_list[blc_id](residual + outputs)\n",
    "\n",
    "        residual = outputs\n",
    "        blc_id = 3\n",
    "        set_id = 0\n",
    "        set_voxel_inds = set_voxel_inds_tensor_shift_1[set_id:set_id+1].squeeze(0)\n",
    "        set_voxel_masks = set_voxel_masks_tensor_shift_1[set_id:set_id+1].squeeze(0)\n",
    "        pos_embed = pos_embed_tensor[blc_id:blc_id+1, set_id:set_id+1].squeeze(0).squeeze(0)\n",
    "        # inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed, True)\n",
    "        inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed)\n",
    "        outputs = self.dsvtblocks_list[blc_id].encoder_list[set_id](*inputs)\n",
    "        set_id = 1\n",
    "        set_voxel_inds = set_voxel_inds_tensor_shift_1[set_id:set_id+1].squeeze(0)\n",
    "        set_voxel_masks = set_voxel_masks_tensor_shift_1[set_id:set_id+1].squeeze(0)\n",
    "        pos_embed = pos_embed_tensor[blc_id:blc_id+1, set_id:set_id+1].squeeze(0).squeeze(0)\n",
    "        inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed)\n",
    "        # inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed, True)\n",
    "        outputs = self.dsvtblocks_list[blc_id].encoder_list[set_id](*inputs)\n",
    "\n",
    "        outputs = self.layer_norms_list[blc_id](residual + outputs)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa75325f-2038-4319-9515-bd95bc9a5871",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-09 04:09:43,743   INFO  Loading Custom dataset.\n",
      "2024-03-09 04:09:43,745   INFO  Total samples for CUSTOM dataset: 0\n"
     ]
    }
   ],
   "source": [
    "# cfg_file = \"./onnx_config.yaml\"\n",
    "cfg_file = \"../tools/cfgs/waymo_models/dsvt_pillar.yaml\"\n",
    "cfg_from_yaml_file(cfg_file, cfg)\n",
    "if os.path.exists('./deploy_files_test')==False:\n",
    "    os.mkdir('./deploy_files_test')\n",
    "log_file = './deploy_files_test/log_trt.log'\n",
    "logger = common_utils.create_logger(log_file, rank=0)\n",
    "test_set, test_loader, sampler = build_dataloader(\n",
    "    dataset_cfg=cfg.DATA_CONFIG,\n",
    "    class_names=cfg.CLASS_NAMES,\n",
    "    batch_size=1,\n",
    "    dist=False, workers=8, logger=logger, training=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "657d9d46-db74-4033-9e7f-e1c66a0be44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ROOT_DIR': PosixPath('/opt/dec'),\n",
       " 'LOCAL_RANK': 0,\n",
       " 'CLASS_NAMES': ['Person'],\n",
       " 'DATA_CONFIG': {'BALANCED_RESAMPLING': False,\n",
       "  'DATASET': 'CustomDataset',\n",
       "  'DATA_AUGMENTOR': {'AUG_CONFIG_LIST': [{'DATABASE_WITH_FAKELIDAR': False,\n",
       "     'DB_INFO_PATH': ['custom_dbinfos_train.pkl'],\n",
       "     'LIMIT_WHOLE_SCENE': True,\n",
       "     'NAME': 'gt_sampling',\n",
       "     'NUM_POINT_FEATURES': 4,\n",
       "     'PREPARE': {'filter_by_min_points': ['Person:3']},\n",
       "     'REMOVE_EXTRA_WIDTH': [0.0, 0.0, 0.0],\n",
       "     'SAMPLE_GROUPS': ['Person:0'],\n",
       "     'USE_ROAD_PLANE': False},\n",
       "    {'ALONG_AXIS_LIST': ['x', 'y'], 'NAME': 'random_world_flip'},\n",
       "    {'NAME': 'random_world_rotation',\n",
       "     'WORLD_ROT_ANGLE': [-0.78539816, 0.78539816]},\n",
       "    {'NAME': 'random_world_scaling', 'WORLD_SCALE_RANGE': [0.95, 1.05]}],\n",
       "   'DISABLE_AUG_LIST': ['placeholder'],\n",
       "   'MIX': {'ALPHA': 2,\n",
       "    'COLLISION_DETECTION': True,\n",
       "    'NAME_LIST': ['mix_up', 'cut_mix'],\n",
       "    'PROB': 0.3}},\n",
       "  'DATA_PATH': '/opt/ml/input/data/cache_pointcloud/7b0fb3d3-2c5b-4721-8e5f-47eae2c02a9c/20ddb47c-40f0-4f8b-9a39-6a47d403ae9c/custom/',\n",
       "  'DATA_PROCESSOR': [{'NAME': 'mask_points_and_boxes_outside_range',\n",
       "    'REMOVE_OUTSIDE_BOXES': True},\n",
       "   {'NAME': 'shuffle_points',\n",
       "    'SHUFFLE_ENABLED': {'test': False, 'train': True}},\n",
       "   {'NAME': 'transform_points_to_voxels_placeholder',\n",
       "    'VOXEL_SIZE': [0.32, 0.32, 6]}],\n",
       "  'DATA_SPLIT': {'test': 'val', 'train': 'train'},\n",
       "  'INFO_PATH': {'test': ['custom_infos_val.pkl'],\n",
       "   'train': ['custom_infos_train.pkl']},\n",
       "  'MAP_CLASS_TO_KITTI': {'Person': 'Person'},\n",
       "  'OFFSET_Z': -2,\n",
       "  'POINT_CLOUD_RANGE': [-74.88, -74.88, -2, 74.88, 74.88, 4],\n",
       "  'POINT_FEATURE_ENCODING': {'encoding_type': 'absolute_coordinates_encoding',\n",
       "   'src_feature_list': ['x', 'y', 'z', 'intensity'],\n",
       "   'used_feature_list': ['x', 'y', 'z', 'intensity']}},\n",
       " 'GENERAL_MODEL': False,\n",
       " 'HOOK': {'DisableAugmentationHook': {'DISABLE_AUG_LIST': ['gt_sampling',\n",
       "    'random_world_flip',\n",
       "    'random_world_rotation',\n",
       "    'random_world_scaling',\n",
       "    'random_world_translation'],\n",
       "   'NUM_LAST_EPOCHS': 1}},\n",
       " 'MODEL': {'BACKBONE_2D': {'LAYER_NUMS': [1, 2, 2],\n",
       "   'LAYER_STRIDES': [1, 2, 2],\n",
       "   'NAME': 'BaseBEVResBackbone',\n",
       "   'NUM_FILTERS': [128, 128, 256],\n",
       "   'NUM_UPSAMPLE_FILTERS': [128, 128, 128],\n",
       "   'UPSAMPLE_STRIDES': [1, 2, 4]},\n",
       "  'BACKBONE_3D': {'INPUT_LAYER': {'d_model': [192],\n",
       "    'downsample_stride': [],\n",
       "    'hybrid_factor': [2, 2, 1],\n",
       "    'normalize_pos': False,\n",
       "    'set_info': [[36, 4]],\n",
       "    'shifts_list': [[[0, 0, 0], [6, 6, 0]]],\n",
       "    'sparse_shape': [468, 468, 1],\n",
       "    'window_shape': [[12, 12, 1]]},\n",
       "   'NAME': 'DSVT',\n",
       "   'USE_CHECKPOINT': False,\n",
       "   'activation': 'gelu',\n",
       "   'block_name': ['DSVTBlock'],\n",
       "   'conv_out_channel': 192,\n",
       "   'd_model': [192],\n",
       "   'dim_feedforward': [384],\n",
       "   'dropout': 0.05,\n",
       "   'nhead': [8],\n",
       "   'output_shape': [468, 468],\n",
       "   'set_info': [[36, 4]]},\n",
       "  'DENSE_HEAD': {'BN_EPS': 0.001,\n",
       "   'BN_MOM': 0.01,\n",
       "   'CLASS_AGNOSTIC': False,\n",
       "   'CLASS_NAMES_EACH_HEAD': [['Person']],\n",
       "   'IOU_REG_LOSS': True,\n",
       "   'LOSS_CONFIG': {'LOSS_WEIGHTS': {'cls_weight': 1.0,\n",
       "     'code_weights': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
       "     'loc_weight': 2.0}},\n",
       "   'NAME': 'CenterHead',\n",
       "   'NUM_HM_CONV': 2,\n",
       "   'POST_PROCESSING': {'IOU_RECTIFIER': [0.65],\n",
       "    'MAX_OBJ_PER_SAMPLE': 500,\n",
       "    'NMS_CONFIG': {'NMS_POST_MAXSIZE': [500],\n",
       "     'NMS_PRE_MAXSIZE': [4096],\n",
       "     'NMS_THRESH': [0.5],\n",
       "     'NMS_TYPE': 'class_specific_nms'},\n",
       "    'POST_CENTER_LIMIT_RANGE': [-80, -80, -10.0, 80, 80, 10.0],\n",
       "    'SCORE_THRESH': 0.1,\n",
       "    'USE_IOU_TO_RECTIFY_SCORE': True},\n",
       "   'SEPARATE_HEAD_CFG': {'HEAD_DICT': {'center': {'num_conv': 2,\n",
       "      'out_channels': 2},\n",
       "     'center_z': {'num_conv': 2, 'out_channels': 1},\n",
       "     'dim': {'num_conv': 2, 'out_channels': 3},\n",
       "     'iou': {'num_conv': 2, 'out_channels': 1},\n",
       "     'rot': {'num_conv': 2, 'out_channels': 2}},\n",
       "    'HEAD_ORDER': ['center', 'center_z', 'dim', 'rot']},\n",
       "   'SHARED_CONV_CHANNEL': 64,\n",
       "   'TARGET_ASSIGNER_CONFIG': {'FEATURE_MAP_STRIDE': 1,\n",
       "    'GAUSSIAN_OVERLAP': 0.1,\n",
       "    'MIN_RADIUS': 2,\n",
       "    'NUM_MAX_OBJS': 500},\n",
       "   'USE_BIAS_BEFORE_NORM': False},\n",
       "  'MAP_TO_BEV': {'INPUT_SHAPE': [468, 468, 1],\n",
       "   'NAME': 'PointPillarScatter3d',\n",
       "   'NUM_BEV_FEATURES': 192},\n",
       "  'NAME': 'CenterPoint',\n",
       "  'POST_PROCESSING': {'EVAL_METRIC': 'custom',\n",
       "   'NMS_CONFIG': {'MULTI_CLASSES_NMS': False,\n",
       "    'NMS_POST_MAXSIZE': 500,\n",
       "    'NMS_PRE_MAXSIZE': 4096,\n",
       "    'NMS_THRESH': 0.1,\n",
       "    'NMS_TYPE': 'nms_gpu'},\n",
       "   'OUTPUT_RAW_SCORE': False,\n",
       "   'RECALL_THRESH_LIST': [0.3, 0.5, 0.7],\n",
       "   'SCORE_THRESH': 0.1},\n",
       "  'VFE': {'NAME': 'DynamicVoxelVFE',\n",
       "   'NUM_FILTERS': [192, 192],\n",
       "   'USE_ABSLOTE_XYZ': True,\n",
       "   'USE_NORM': True,\n",
       "   'WITH_DISTANCE': False}},\n",
       " 'OPTIMIZATION': {'BATCH_SIZE_PER_GPU': 1,\n",
       "  'DECAY_STEP_LIST': [35, 45],\n",
       "  'DIV_FACTOR': 100,\n",
       "  'GRAD_NORM_CLIP': 10,\n",
       "  'LOSS_SCALE_FP16': 32.0,\n",
       "  'LR': 0.0007,\n",
       "  'LR_CLIP': 1e-07,\n",
       "  'LR_DECAY': 0.1,\n",
       "  'LR_WARMUP': True,\n",
       "  'MOMENTUM': 0.9,\n",
       "  'MOMS': [0.95, 0.85],\n",
       "  'NUM_EPOCHS': 70,\n",
       "  'OPTIMIZER': 'adam_onecycle',\n",
       "  'PCT_START': 0.1,\n",
       "  'WARMUP_EPOCH': 8,\n",
       "  'WEIGHT_DECAY': 0.05}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), dataset=test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbb466c4-a62b-4ab2-b1f7-29a489960051",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-09 04:09:57,277   INFO  ==> Loading parameters from checkpoint ./pillar/model.pth to GPU\n",
      "2024-03-09 04:09:57,424   INFO  ==> Checkpoint trained from version: pcdet+0.6.0+255db8f\n",
      "2024-03-09 04:09:57,457   INFO  ==> Done (loaded 391/391)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CenterPoint(\n",
       "  (vfe): DynamicVoxelVFE(\n",
       "    (pfn_layers): ModuleList(\n",
       "      (0): PFNLayerV2(\n",
       "        (linear): Linear(in_features=10, out_features=96, bias=False)\n",
       "        (norm): BatchNorm1d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): PFNLayerV2(\n",
       "        (linear): Linear(in_features=192, out_features=192, bias=False)\n",
       "        (norm): BatchNorm1d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (backbone_3d): DSVT(\n",
       "    (input_layer): DSVTInputLayer(\n",
       "      (posembed_layers): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0-3): 4 x ModuleList(\n",
       "            (0-1): 2 x PositionEmbeddingLearned(\n",
       "              (position_embedding_head): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=192, bias=True)\n",
       "                (1): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "                (3): Linear(in_features=192, out_features=192, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (stage_0): ModuleList(\n",
       "      (0-3): 4 x DSVTBlock(\n",
       "        (encoder_list): ModuleList(\n",
       "          (0-1): 2 x DSVT_EncoderLayer(\n",
       "            (win_attn): SetAttention(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "              )\n",
       "              (linear1): Linear(in_features=192, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0, inplace=False)\n",
       "              (linear2): Linear(in_features=384, out_features=192, bias=True)\n",
       "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout1): Identity()\n",
       "              (dropout2): Identity()\n",
       "            )\n",
       "            (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (residual_norm_stage_0): ModuleList(\n",
       "      (0-3): 4 x LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (map_to_bev_module): PointPillarScatter3d()\n",
       "  (pfe): None\n",
       "  (backbone_2d): BaseBEVResBackbone(\n",
       "    (blocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU()\n",
       "          (downsample_layer): Sequential(\n",
       "            (0): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU()\n",
       "          (downsample_layer): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU()\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU()\n",
       "          (downsample_layer): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU()\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (deblocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ConvTranspose2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(4, 4), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dense_head): CenterHead(\n",
       "    (shared_conv): Sequential(\n",
       "      (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (heads_list): ModuleList(\n",
       "      (0): SeparateHead(\n",
       "        (center): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (center_z): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (dim): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (iou): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (rot): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (hm): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (hm_loss_func): FocalLossCenterNet()\n",
       "    (reg_loss_func): RegLossCenterNet()\n",
       "  )\n",
       "  (point_head): None\n",
       "  (roi_head): None\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = \"/mnt/nas2/users/eslim/result_log/dsvt_pillar_waymo/ckpt/latest_model.pth\"\n",
    "model.load_params_from_file(filename=ckpt, logger=logger, to_cpu=False, pre_trained_path=None)\n",
    "model.eval()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bfa6d63-b83b-48b7-8214-57a532a1d31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_dict = torch.load(\"./batch_dict.pth\", map_location=\"cuda\")\n",
    "inputs = batch_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "465822a2-6d58-497a-a330-280db138ccdf",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (125027x11 and 10x96)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m dsvtblocks_list \u001b[38;5;241m=\u001b[39m DSVT_Backbone\u001b[38;5;241m.\u001b[39mstage_0\n\u001b[1;32m      4\u001b[0m layer_norms_list \u001b[38;5;241m=\u001b[39m DSVT_Backbone\u001b[38;5;241m.\u001b[39mresidual_norm_stage_0\n\u001b[0;32m----> 5\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvfe\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m voxel_info \u001b[38;5;241m=\u001b[39m DSVT_Backbone\u001b[38;5;241m.\u001b[39minput_layer(inputs)\n\u001b[1;32m      7\u001b[0m set_voxel_inds_list \u001b[38;5;241m=\u001b[39m [[voxel_info[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mset_voxel_inds_stage\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_shift\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m)] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m)]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/dec/pcdet/models/backbones_3d/vfe/dynamic_voxel_vfe.py:93\u001b[0m, in \u001b[0;36mDynamicVoxelVFE.forward\u001b[0;34m(self, batch_dict, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(features, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pfn \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpfn_layers:\n\u001b[0;32m---> 93\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[43mpfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munq_inv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# generate voxel coordinates\u001b[39;00m\n\u001b[1;32m     96\u001b[0m unq_coords \u001b[38;5;241m=\u001b[39m unq_coords\u001b[38;5;241m.\u001b[39mint()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/dec/pcdet/models/backbones_3d/vfe/dynamic_pillar_vfe.py:37\u001b[0m, in \u001b[0;36mPFNLayerV2.forward\u001b[0;34m(self, inputs, unq_inv)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, unq_inv):\n\u001b[0;32m---> 37\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_norm \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[1;32m     39\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (125027x11 and 10x96)"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    DSVT_Backbone = model.backbone_3d\n",
    "    dsvtblocks_list = DSVT_Backbone.stage_0\n",
    "    layer_norms_list = DSVT_Backbone.residual_norm_stage_0\n",
    "    inputs = model.vfe(inputs)\n",
    "    voxel_info = DSVT_Backbone.input_layer(inputs)\n",
    "    set_voxel_inds_list = [[voxel_info[f'set_voxel_inds_stage{s}_shift{i}'] for i in range(2)] for s in range(1)]\n",
    "    set_voxel_masks_list = [[voxel_info[f'set_voxel_mask_stage{s}_shift{i}'] for i in range(2)] for s in range(1)]\n",
    "    pos_embed_list = [[[voxel_info[f'pos_embed_stage{s}_block{b}_shift{i}'] for i in range(2)] for b in range(4)] for s in range(1)]\n",
    "\n",
    "    pillar_features = inputs['voxel_features']\n",
    "    alldsvtblockstrt_inputs = (\n",
    "        pillar_features,\n",
    "        set_voxel_inds_list[0][0],\n",
    "        set_voxel_inds_list[0][1],\n",
    "        set_voxel_masks_list[0][0],\n",
    "        set_voxel_masks_list[0][1],\n",
    "        torch.stack([torch.stack(v, dim=0) for v in pos_embed_list[0]], dim=0),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcf6653b-c604-4643-be2a-1c4b9ab059d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "jit_mode = \"trace\"\n",
    "input_names = [\n",
    "    'src',\n",
    "    'set_voxel_inds_tensor_shift_0',\n",
    "    'set_voxel_inds_tensor_shift_1',\n",
    "    'set_voxel_masks_tensor_shift_0',\n",
    "    'set_voxel_masks_tensor_shift_1',\n",
    "    'pos_embed_tensor'\n",
    "]\n",
    "output_names = [\"output\",]\n",
    "input_shapes = {\n",
    "    \"src\": {\n",
    "        \"min_shape\": [24629, 192],\n",
    "        \"opt_shape\": [24629, 192],\n",
    "        \"max_shape\": [24629, 192],\n",
    "    },\n",
    "    \"set_voxel_inds_tensor_shift_0\": {\n",
    "        \"min_shape\": [2, 1156, 36],\n",
    "        \"opt_shape\": [2, 1156, 36],\n",
    "        \"max_shape\": [2, 1156, 36],\n",
    "    },\n",
    "    \"set_voxel_inds_tensor_shift_1\": {\n",
    "        \"min_shape\": [2, 834, 36],\n",
    "        \"opt_shape\": [2, 834, 36],\n",
    "        \"max_shape\": [2, 834, 36],\n",
    "    },\n",
    "    \"set_voxel_masks_tensor_shift_0\": {\n",
    "        \"min_shape\": [2, 1156, 36],\n",
    "        \"opt_shape\": [2, 1156, 36],\n",
    "        \"max_shape\": [2, 1156, 36],\n",
    "    },\n",
    "    \"set_voxel_masks_tensor_shift_1\": {\n",
    "        \"min_shape\": [2, 834, 36],\n",
    "        \"opt_shape\": [2, 834, 36],\n",
    "        \"max_shape\": [2, 834, 36],\n",
    "    },\n",
    "    \"pos_embed_tensor\": {\n",
    "        \"min_shape\": [4, 2, 24629, 192],\n",
    "        \"opt_shape\": [4, 2, 24629, 192],\n",
    "        \"max_shape\": [4, 2, 24629, 192],\n",
    "    },\n",
    "}\n",
    "\n",
    "dynamic_axes = {\n",
    "    \"src\": {\n",
    "        0: \"voxel_number\",\n",
    "    },\n",
    "    \"set_voxel_inds_tensor_shift_0\": {\n",
    "        1: \"set_number_shift_0\",\n",
    "    },\n",
    "    \"set_voxel_inds_tensor_shift_1\": {\n",
    "        1: \"set_number_shift_1\",\n",
    "    },\n",
    "    \"set_voxel_masks_tensor_shift_0\": {\n",
    "        1: \"set_number_shift_0\",\n",
    "    },\n",
    "    \"set_voxel_masks_tensor_shift_1\": {\n",
    "        1: \"set_number_shift_1\",\n",
    "    },\n",
    "    \"pos_embed_tensor\": {\n",
    "        2: \"voxel_number\",\n",
    "    },\n",
    "    \"output\": {\n",
    "        0: \"voxel_number\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c02e25f-9ab5-4a0e-946b-1a112e8f3e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_name = \"./deploy_files_test/dsvt\"\n",
    "ts_path = f\"{base_name}.ts\"\n",
    "onnx_path = f\"{base_name}.onnx\"\n",
    "\n",
    "allptransblocktrt = AllDSVTBlocksTRT(dsvtblocks_list, layer_norms_list).eval().cuda()\n",
    "\n",
    "torch.onnx.export(\n",
    "    allptransblocktrt,\n",
    "    alldsvtblockstrt_inputs,\n",
    "    onnx_path, input_names=input_names,\n",
    "    output_names=output_names, dynamic_axes=dynamic_axes,\n",
    "    opset_version=14,\n",
    ")\n",
    "# https://github.com/Haiyang-W/DSVT/issues/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94806e45-a969-4b21-93f2-79143b2911d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.00120146,  0.0012869 ,  0.13761668, ..., -0.04611877,\n",
       "          0.005659  , -0.02467331],\n",
       "        [-0.00172799, -0.00854082, -0.05844514, ..., -0.08249708,\n",
       "          0.00571191,  0.03585856],\n",
       "        [-0.00201712,  0.02557927,  0.12964977, ..., -0.07701403,\n",
       "          0.00571428,  0.2548802 ],\n",
       "        ...,\n",
       "        [-0.00198825,  0.03332692,  0.07325681, ..., -0.07479647,\n",
       "          0.00561676, -0.14559093],\n",
       "        [-0.00226119, -0.01397068,  0.13979352, ...,  0.11101341,\n",
       "          0.00556513, -0.24747433],\n",
       "        [-0.00113338,  0.02863011, -0.04145716, ...,  0.05549115,\n",
       "          0.00571733, -0.25773776]], dtype=float32)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test onnx\n",
    "ort_session = ort.InferenceSession(onnx_path)\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# compute ONNX Runtime output prediction\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(pillar_features),\n",
    "              ort_session.get_inputs()[1].name: to_numpy(set_voxel_inds_list[0][0]),\n",
    "              ort_session.get_inputs()[2].name: to_numpy(set_voxel_inds_list[0][1]),\n",
    "              ort_session.get_inputs()[3].name: to_numpy(set_voxel_masks_list[0][0]),\n",
    "              ort_session.get_inputs()[4].name: to_numpy(set_voxel_masks_list[0][1]),\n",
    "              ort_session.get_inputs()[5].name: to_numpy(torch.stack([torch.stack(v, dim=0) for v in pos_embed_list[0]], dim=0)),}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "ort_outs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
